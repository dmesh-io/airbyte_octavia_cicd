# Configuration for airbyte/source-file
# Documentation about this connector can be found at https://docs.airbyte.com/integrations/sources/file
resource_name: "fileS3"
definition_type: source
definition_id: 778daa7c-feaf-4db6-96f3-70fd645acc77
definition_image: airbyte/source-file
definition_version: 0.3.11

# EDIT THE CONFIGURATION BELOW!
configuration:
  url: s3://gdelt-open-data/events/20190914.export.csv # REQUIRED | string | The URL path to access the file which should be replicated. | Examples: https://storage.googleapis.com/covid19-open-data/v2/latest/epidemiology.csv, gs://my-google-bucket/data.csv, s3://gdelt-open-data/events/20190914.export.csv
  format: "csv" # REQUIRED | string | The Format of the file which should be replicated (Warning: some formats may be experimental, please refer to the docs).
  provider:
    ## -------- Pick one valid structure among the examples below: --------
    # storage: "HTTPS" # REQUIRED | string
    # user_agent: # OPTIONAL | boolean | Add User-Agent to request
    ## -------- Another valid structure for provider: --------
    # storage: "GCS" # REQUIRED | string
    # service_account_json: ${SERVICE_ACCOUNT_JSON} # SECRET (please store in environment variables) | OPTIONAL | string | In order to access private Buckets stored on Google Cloud, this connector would need a service account json credentials with the proper permissions as described <a href="https://cloud.google.com/iam/docs/service-accounts" target="_blank">here</a>. Please generate the credentials.json file and copy/paste its content to this field (expecting JSON formats). If accessing publicly available data, this field is not necessary.
    ## -------- Another valid structure for provider: --------
    storage: "S3" # REQUIRED | string
    # aws_access_key_id: # OPTIONAL | string | In order to access private Buckets stored on AWS S3, this connector would need credentials with the proper permissions. If accessing publicly available data, this field is not necessary.
    # aws_secret_access_key: ${AWS_SECRET_ACCESS_KEY} # SECRET (please store in environment variables) | OPTIONAL | string | In order to access private Buckets stored on AWS S3, this connector would need credentials with the proper permissions. If accessing publicly available data, this field is not necessary.
    ## -------- Another valid structure for provider: --------
    # storage: "AzBlob" # REQUIRED | string
    # sas_token: ${SAS_TOKEN} # SECRET (please store in environment variables) | OPTIONAL | string | To access Azure Blob Storage, this connector would need credentials with the proper permissions. One option is a SAS (Shared Access Signature) token. If accessing publicly available data, this field is not necessary.
    # shared_key: ${SHARED_KEY} # SECRET (please store in environment variables) | OPTIONAL | string | To access Azure Blob Storage, this connector would need credentials with the proper permissions. One option is a storage account shared key (aka account key or access key). If accessing publicly available data, this field is not necessary.
    # storage_account: # REQUIRED | string | The globally unique name of the storage account that the desired blob sits within. See <a href="https://docs.microsoft.com/en-us/azure/storage/common/storage-account-overview" target="_blank">here</a> for more details.
    ## -------- Another valid structure for provider: --------
    # host: # REQUIRED | string
    # port: "22" # OPTIONAL | string
    # user: # REQUIRED | string
    # storage: "SSH" # REQUIRED | string
    # password: ${PASSWORD} # SECRET (please store in environment variables) | OPTIONAL | string
    ## -------- Another valid structure for provider: --------
    # host: # REQUIRED | string
    # port: "22" # OPTIONAL | string
    # user: # REQUIRED | string
    # storage: "SCP" # REQUIRED | string
    # password: ${PASSWORD} # SECRET (please store in environment variables) | OPTIONAL | string
    ## -------- Another valid structure for provider: --------
    # host: # REQUIRED | string
    # port: "22" # OPTIONAL | string
    # user: # REQUIRED | string
    # storage: "SFTP" # REQUIRED | string
    # password: ${PASSWORD} # SECRET (please store in environment variables) | OPTIONAL | string
    ## -------- Another valid structure for provider: --------
    # storage: "local" # REQUIRED | string | WARNING: Note that the local storage URL available for reading must start with the local mount "/local/" at the moment until we implement more advanced docker mounting options.
  dataset_name: foobar # REQUIRED | string | The Name of the final table to replicate this file into (should include letters, numbers dash and underscores only).
  reader_options: "{'sep': '\t'}" # OPTIONAL | string | This should be a string in JSON format. It depends on the chosen file format to provide additional options and tune its behavior. | Examples: {}, {"sep": " "}, {"sep": "	", "header": 0, "names": ["column1", "column2"] }
